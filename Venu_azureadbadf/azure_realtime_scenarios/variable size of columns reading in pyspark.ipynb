{"cells":[{"cell_type":"markdown","source":["#### Importing text file with varying number of columns in PySpark?\n#### variable size of columns reading in pyspark?\n#### How to create dynamic columns with variable size of columns in pyspark dataframe?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e638c112-fcf3-43ce-a467-4c9f3ddea5ac"}}},{"cell_type":"code","source":["dbutils.fs.put(\"/scenario_files/dynamicolumns.csv\",\n\"\"\"\nid,name,loc,age,sex\n1,ravi,bangalore,33,m\n2,raj,chennai\n3,mohan\n4,prasad,hyderabad,35\n5,sridhar,chennai\n\"\"\",True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9ca92a7-e124-4456-b837-bfcc114afba7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.read.csv(\"/scenario_files/dynamicolumns.csv\",header=True)\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a125749-9842-4dc2-b835-eae24571e935"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.put(\"/scenario_files/dynamicolumns_withoutheader.csv\",\n\"\"\"1,ravi,bangalore\n2,raj,chennai,33,m\n3,mohan\n4,prasad,hyderabad,35,m,787878987\n5,sridhar,chennai\n\"\"\",True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"563a6c98-5f62-4ef4-8105-0cd6747911ca"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df1 = spark.read.csv(\"/scenario_files/dynamicolumns_withoutheader.csv\")\ndisplay(df1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9562ac1d-f85c-4bcb-a32d-3487c56c0997"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create Dataframe reading csv file using spark.read.text api\ndf1 = spark.read.text(\"/scenario_files/dynamicolumns_withoutheader.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"603f79b3-9c5c-4c9b-9188-fd9d63314079"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import split,length,col,max,size\n# Split text data using split function with comma delimieter\ndf3 =df1.select(split(\"value\",\",\").alias(\"splitted_col\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0444f30-17ee-4364-bf6c-4f431fa11952"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Get Length of each row using size function then find max length of row for generating no of columns dynamically\ndf3.select('splitted_col',size('splitted_col')).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42052941-06e2-49f4-8a75-f171e30c7edf"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Verify no of columns is going to generate this from data.\ndf3.select(max(size('splitted_col'))).collect()[0][0]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30f47315-6e2b-4f7f-992b-27fea09c19ac"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Getting Max Index value for generating dynamic columns using max size of items at each row.\nfor i in range(df3.select(max(size('splitted_col'))).collect()[0][0]):\n    # Dynamically Add Columns using WithColumn \n    df3=df3.withColumn('col'+str(i),df3[\"splitted_col\"][i])\n# Drop splitted_Col which is not required after splitting into individual columns\ndf3 = df3.drop(\"splitted_col\")\ndf3.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c39417f1-4dd3-4c3d-99a6-d833405edc0c"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"variable size of columns reading in pyspark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":570886976656667}},"nbformat":4,"nbformat_minor":0}
